{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_kheperaposition\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "Vmax=0.05\n",
    "Wmax=math.pi/4\n",
    "L=0.1\n",
    "Kr_V_RL=0.05   # radio de seguridad\n",
    "\n",
    "def random_agent(steps=900):\n",
    "    episode_reward = 0\n",
    "    env = gym.make('KheperaPositionControl-v0')\n",
    "    env.MaxSteps = steps\n",
    "    state = env.reset()\n",
    "    d, Oc = state\n",
    "    states = [] \n",
    "    #env.render()\n",
    "    \n",
    "    data = {}\n",
    "    paso = []\n",
    "    infoOc = []\n",
    "    infoD = []\n",
    "    Lineal = []\n",
    "    Angular = []\n",
    "    xc = []\n",
    "    yc = []\n",
    "    \n",
    "    for e in range(steps):\n",
    "        w = Wmax*math.sin(Oc)\n",
    "        if d > Kr_V_RL:\n",
    "            v = Vmax\n",
    "        else:\n",
    "            v = d*(Vmax/Kr_V_RL)\n",
    "        if d < 0.02:\n",
    "            v = 0\n",
    "            w = 0\n",
    "        states.append([state, e])\n",
    "        Vl = (v-(w*0.1)/2)*48\n",
    "        Vr = (v+(w*0.1)/2)*48\n",
    "        action = [Vl, Vr]\n",
    "        state, reward, done, info = env.step(action)\n",
    "        d, Oc = state\n",
    "        \n",
    "        #env.render()\n",
    "        #print(reward)\n",
    "        print(reward, end='\\r')\n",
    "        sys.stdout.flush()\n",
    "        episode_reward += reward\n",
    "        \n",
    "        x = info['xc']\n",
    "        y = info['yc']\n",
    "        \n",
    "        paso.append(e)\n",
    "        infoOc.append(float(Oc))\n",
    "        infoD.append(float(d))\n",
    "        Lineal.append(float(v))\n",
    "        Angular.append(float(w))\n",
    "        xc.append(np.array(x))\n",
    "        yc.append(np.array(y))\n",
    "        \n",
    "        if done:\n",
    "            print('Reward of the episode is: ',episode_reward)\n",
    "            break\n",
    "    \n",
    "    env.close()\n",
    "    data={'paso' : paso,\n",
    "          'Oc' : infoOc,\n",
    "          'Distance' : infoD,\n",
    "          'Lineal' : Lineal,\n",
    "          'Angular' : Angular,\n",
    "          'xc' : xc,\n",
    "          'yc' : yc\n",
    "    }\n",
    "    return data\n",
    "data1 = random_agent()\n",
    "\n",
    "d, t, v, w = [np.array(data1['Distance']), 0.05*np.array(data1['paso']), np.array(data1['Lineal']), np.array(data1['Angular'])]\n",
    "\n",
    "IAE = np.trapz(abs(d),t)\n",
    "ISE = np.trapz(d**2,t)\n",
    "ITAE = np.trapz(t*abs(d),t)\n",
    "ITSE = np.trapz(t*(d**2),t)\n",
    "\n",
    "Villela = [ISE, IAE, ITSE, ITAE]\n",
    "\n",
    "print(IAE)\n",
    "print(ISE)\n",
    "print(ITAE)\n",
    "print(ITSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
